{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP7sx996Tdf2vWptJ0d5F7w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"v3Mo3sHuv-pV","executionInfo":{"status":"ok","timestamp":1731203222306,"user_tz":-330,"elapsed":424,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"outputs":[],"source":["#Step 1: Setting Up the Perceptron Class\n","\n","#This class will initialize the perceptron, define the step function, and include the training process."]},{"cell_type":"code","source":["import numpy as np\n","\n","class Perceptron:\n","    def __init__(self, learning_rate=0.1, epochs=10):\n","        # Initialize learning rate and epochs\n","        self.learning_rate = learning_rate\n","        self.epochs = epochs\n","        # Initialize weights and bias with random values\n","        self.weights = np.random.rand(2)\n","        self.bias = np.random.rand(1)\n","\n","    def step_function(self, x):\n","        # Step function as activation function\n","        return 1 if x >= 0 else 0\n","\n","    def predict(self, x):\n","        # Calculate weighted sum and apply step function\n","        weighted_sum = np.dot(self.weights, x) + self.bias\n","        return self.step_function(weighted_sum)\n","\n","    def train(self, X, y):\n","        # Training process\n","        for epoch in range(self.epochs):\n","            for inputs, label in zip(X, y):\n","                prediction = self.predict(inputs)\n","                error = label - prediction\n","\n","                # Update weights and bias based on error\n","                self.weights += self.learning_rate * error * inputs\n","                self.bias += self.learning_rate * error\n","            # Optional: Print the progress at each epoch\n","            print(f\"Epoch {epoch+1}/{self.epochs}, Weights: {self.weights}, Bias: {self.bias}\")\n"],"metadata":{"id":"RnUNcD0gwKB3","executionInfo":{"status":"ok","timestamp":1731203252105,"user_tz":-330,"elapsed":503,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#Step 2: Setting Up the Dataset and Training the Perceptron\n","\n","#Define the dataset according to the problem description and then train the perceptron."],"metadata":{"id":"EB4DEzMRwTmm","executionInfo":{"status":"ok","timestamp":1731203289373,"user_tz":-330,"elapsed":491,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Sample dataset: inputs and expected outputs\n","X = np.array([\n","    [0.1, 0.1],  # Expected output 0\n","    [0.1, 0.9],  # Expected output 0\n","    [0.9, 0.1],  # Expected output 0\n","    [0.9, 0.9]   # Expected output 1\n","])\n","y = np.array([0, 0, 0, 1])\n","\n","# Initialize the perceptron with a learning rate of 0.1 and 10 epochs\n","perceptron = Perceptron(learning_rate=0.1, epochs=10)\n","\n","# Train the perceptron\n","perceptron.train(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0m9mKzdLwcxN","executionInfo":{"status":"ok","timestamp":1731203297977,"user_tz":-330,"elapsed":407,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}},"outputId":"30b5d99a-aedf-432d-db5e-6076fad60e36"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Weights: [-0.06141372  0.25152277], Bias: [0.11803001]\n","Epoch 2/10, Weights: [0.00858628 0.24152277], Bias: [0.01803001]\n","Epoch 3/10, Weights: [0.07858628 0.23152277], Bias: [-0.08196999]\n","Epoch 4/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 5/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 6/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 7/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 8/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 9/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n","Epoch 10/10, Weights: [0.06858628 0.14152277], Bias: [-0.18196999]\n"]}]},{"cell_type":"code","source":["#Step 3: Testing the Trained Perceptron\n","\n","#Test if the perceptron learned correctly by making predictions on the training data."],"metadata":{"id":"_reeeC5Bwe5l","executionInfo":{"status":"ok","timestamp":1731203326709,"user_tz":-330,"elapsed":498,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Testing the perceptron\n","print(\"\\nTesting Perceptron on Training Data:\")\n","for x in X:\n","    prediction = perceptron.predict(x)\n","    print(f\"Input: {x}, Prediction: {prediction}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EigmUREzwlzz","executionInfo":{"status":"ok","timestamp":1731203335349,"user_tz":-330,"elapsed":413,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}},"outputId":"f02d2862-4d22-481d-8b0e-4b8ef45fa559"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Testing Perceptron on Training Data:\n","Input: [0.1 0.1], Prediction: 0\n","Input: [0.1 0.9], Prediction: 0\n","Input: [0.9 0.1], Prediction: 0\n","Input: [0.9 0.9], Prediction: 1\n"]}]},{"cell_type":"code","source":["#Part 3: Modifications and Experimentation\n","\n","#To experiment with the parameters, you can modify the learning rate, number of epochs, and dataset as follows:\n","\n","# 1.Change Learning Rate:"],"metadata":{"id":"4KObbCuOwoAy","executionInfo":{"status":"ok","timestamp":1731203364548,"user_tz":-330,"elapsed":456,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Re-initialize perceptron with a different learning rate\n","perceptron = Perceptron(learning_rate=0.5, epochs=10)\n","perceptron.train(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qO0kjtqQwvJE","executionInfo":{"status":"ok","timestamp":1731203374467,"user_tz":-330,"elapsed":468,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}},"outputId":"d5a5001a-15a6-4a21-de42-85db46614f56"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Weights: [0.44574352 0.04271735], Bias: [-0.34508304]\n","Epoch 2/10, Weights: [0.44574352 0.44271735], Bias: [-0.34508304]\n","Epoch 3/10, Weights: [0.84574352 0.44271735], Bias: [-0.34508304]\n","Epoch 4/10, Weights: [1.24574352 0.44271735], Bias: [-0.34508304]\n","Epoch 5/10, Weights: [1.19574352 0.39271735], Bias: [-0.84508304]\n","Epoch 6/10, Weights: [1.19574352 0.79271735], Bias: [-0.84508304]\n","Epoch 7/10, Weights: [1.19574352 1.19271735], Bias: [-0.84508304]\n","Epoch 8/10, Weights: [1.14574352 0.74271735], Bias: [-1.34508304]\n","Epoch 9/10, Weights: [1.14574352 0.74271735], Bias: [-1.34508304]\n","Epoch 10/10, Weights: [1.14574352 0.74271735], Bias: [-1.34508304]\n"]}]},{"cell_type":"code","source":["#2. Increase Epochs:"],"metadata":{"id":"P3e9ktbOwxkD","executionInfo":{"status":"ok","timestamp":1731203407539,"user_tz":-330,"elapsed":411,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Re-initialize perceptron with more epochs\n","perceptron = Perceptron(learning_rate=0.1, epochs=200)\n","perceptron.train(X, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDrcOL-9w5oK","executionInfo":{"status":"ok","timestamp":1731203419625,"user_tz":-330,"elapsed":492,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}},"outputId":"1e34b94e-bf4f-4abb-d917-eafb01bd6235"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200, Weights: [0.65551795 0.0939299 ], Bias: [0.26826044]\n","Epoch 2/200, Weights: [ 0.54551795 -0.0160701 ], Bias: [-0.03173956]\n","Epoch 3/200, Weights: [ 0.44551795 -0.0360701 ], Bias: [-0.23173956]\n","Epoch 4/200, Weights: [0.44551795 0.0439299 ], Bias: [-0.23173956]\n","Epoch 5/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 6/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 7/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 8/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 9/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 10/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 11/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 12/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 13/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 14/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 15/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 16/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 17/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 18/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 19/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 20/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 21/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 22/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 23/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 24/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 25/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 26/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 27/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 28/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 29/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 30/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 31/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 32/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 33/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 34/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 35/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 36/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 37/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 38/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 39/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 40/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 41/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 42/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 43/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 44/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 45/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 46/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 47/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 48/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 49/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 50/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 51/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 52/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 53/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 54/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 55/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 56/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 57/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 58/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 59/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 60/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 61/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 62/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 63/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 64/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 65/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 66/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 67/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 68/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 69/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 70/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 71/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 72/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 73/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 74/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 75/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 76/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 77/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 78/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 79/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 80/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 81/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 82/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 83/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 84/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 85/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 86/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 87/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 88/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 89/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 90/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 91/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 92/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 93/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 94/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 95/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 96/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 97/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 98/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 99/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 100/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 101/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 102/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 103/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 104/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 105/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 106/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 107/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 108/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 109/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 110/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 111/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 112/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 113/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 114/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 115/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 116/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 117/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 118/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 119/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 120/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 121/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 122/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 123/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 124/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 125/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 126/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 127/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 128/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 129/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 130/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 131/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 132/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 133/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 134/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 135/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 136/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 137/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 138/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 139/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 140/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 141/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 142/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 143/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 144/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 145/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 146/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 147/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 148/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 149/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 150/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 151/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 152/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 153/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 154/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 155/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 156/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 157/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 158/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 159/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 160/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 161/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 162/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 163/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 164/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 165/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 166/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 167/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 168/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 169/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 170/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 171/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 172/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 173/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 174/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 175/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 176/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 177/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 178/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 179/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 180/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 181/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 182/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 183/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 184/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 185/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 186/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 187/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 188/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 189/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 190/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 191/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 192/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 193/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 194/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 195/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 196/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 197/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 198/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 199/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n","Epoch 200/200, Weights: [0.35551795 0.0339299 ], Bias: [-0.33173956]\n"]}]},{"cell_type":"code","source":["# 3.Add Edge Cases:"],"metadata":{"id":"k-wKaZusw8lN","executionInfo":{"status":"ok","timestamp":1731203448584,"user_tz":-330,"elapsed":392,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[" # Modify dataset with edge cases\n","X_edge = np.array([\n","    [0.1, 0.1], [0.1, 0.9], [0.9, 0.1], [0.9, 0.9],\n","    [0.49, 0.51], [0.51, 0.49], [0.6, 0.6], [0.4, 0.4]\n","])\n","y_edge = np.array([0, 0, 0, 1, 0, 0, 1, 0])\n","\n","# Train with edge cases\n","perceptron = Perceptron(learning_rate=0.1, epochs=10)\n","perceptron.train(X_edge, y_edge)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bezp7tM_xDq3","executionInfo":{"status":"ok","timestamp":1731203451900,"user_tz":-330,"elapsed":390,"user":{"displayName":"CodeWithTanzeem","userId":"12078918022143213971"}},"outputId":"342c23bb-d3ea-4bfd-f65a-17a304623e08"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Weights: [ 0.11078039 -0.15770706], Bias: [-0.05366267]\n","Epoch 2/10, Weights: [ 0.13078039 -0.05770706], Bias: [-0.05366267]\n","Epoch 3/10, Weights: [ 0.10178039 -0.00870706], Bias: [-0.15366267]\n","Epoch 4/10, Weights: [0.16278039 0.05029294], Bias: [-0.15366267]\n","Epoch 5/10, Weights: [0.18278039 0.07029294], Bias: [-0.15366267]\n","Epoch 6/10, Weights: [0.19378039 0.15929294], Bias: [-0.15366267]\n","Epoch 7/10, Weights: [0.24478039 0.12829294], Bias: [-0.25366267]\n","Epoch 8/10, Weights: [0.26478039 0.14829294], Bias: [-0.25366267]\n","Epoch 9/10, Weights: [0.28478039 0.16829294], Bias: [-0.25366267]\n","Epoch 10/10, Weights: [0.29578039 0.25729294], Bias: [-0.25366267]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"98hSiO59xEe6"},"execution_count":null,"outputs":[]}]}